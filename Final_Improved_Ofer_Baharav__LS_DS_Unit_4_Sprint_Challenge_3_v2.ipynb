{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Final_Improved_Ofer_Baharav_ LS_DS_Unit_4_Sprint_Challenge_3_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nteract": {
      "version": "0.21.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oferbaharav/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/Final_Improved_Ofer_Baharav__LS_DS_Unit_4_Sprint_Challenge_3_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB6QLCRA7brT",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime locally, on AWS SageMaker, on Colab or on a comparable environment. If something is running longer, double check your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for object detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe a use case for an autoencoder\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - LSTMSs\n",
        "\n",
        "Use a LSTM to fit a multi-class classification model on Reuters news articles to distinguish topics of articles. The data is already encoded properly for use in a LSTM model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well as the LSTM code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "outputId": "b3e147b4-65b3-4684-b701-e0d11c9c595b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnswf635__qj",
        "colab_type": "code",
        "outputId": "4275f302-a9a5-4b07-befd-93cd79e704f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8982,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMDjEExTAEgo",
        "colab_type": "code",
        "outputId": "8de124ab-9a74-4bc5-9391-961d8dddb604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8982,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzg8yN02AHsV",
        "colab_type": "code",
        "outputId": "0ce10924-2be6-4455-f093-7be3c8c01d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2246,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqEtAseYANd_",
        "colab_type": "code",
        "outputId": "92aedd8b-81f2-488f-daba-fd73f8d5be1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2246,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-FFc2I4AZxH",
        "colab_type": "code",
        "outputId": "ceb7731d-6133-4ef6-b1b9-15974d5376c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "X_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 248, 409, 166, 265, 1537, 1662, 8, 24, 4, 1222, 2771, 7, 227, 236, 40, 85, 944, 10, 531, 176, 8, 4, 176, 1613, 24, 1662, 297, 5157, 6, 10, 103, 5, 231, 215, 8, 7, 2889, 6, 10, 1202, 69, 4, 1222, 329, 2771, 24, 944, 23, 944, 1662, 40, 2509, 1592, 907, 69, 4, 113, 997, 762, 2539, 7, 227, 236, 17, 12]),\n",
              "       list([1, 4665, 1183, 413, 381, 7, 1134, 1664, 62, 729, 7, 4, 121, 273, 93, 109, 28, 2115, 72, 11, 428, 4, 387, 989, 558, 3956, 8, 7, 25, 1213, 427, 1969, 223, 4, 213, 5, 387, 580, 8, 1145, 413, 62, 410, 451, 18, 428, 7, 4, 121, 6, 3106, 19, 11, 428, 9, 1283, 317, 65, 413, 138, 59, 12, 11, 428, 6, 6118, 63, 11, 4, 3956, 8, 3640, 1183, 413, 202, 251, 18, 428, 6, 546, 19, 11, 428, 9, 317, 65, 413, 7, 4, 1721, 427, 409, 7145, 138, 19, 19, 11, 428, 6, 3843, 70, 11, 4, 135, 5, 137, 317, 1833, 542, 9, 7145, 413, 138, 72, 47, 11, 428, 6, 19, 5106, 19, 16, 8, 17, 12]),\n",
              "       list([1, 56, 14065, 65, 9, 249, 149, 8, 4, 347, 5, 25, 65, 9, 249, 282, 333, 27, 258, 20, 6, 644, 59, 11, 15, 22, 653, 32, 11, 15, 257, 28, 29, 153, 105, 519, 6, 42, 1436, 7233, 14065, 8, 16, 40, 282, 5, 32, 47, 11, 428, 5, 65, 9, 659, 249, 3264, 9, 934, 32, 35, 1396, 983, 5, 659, 249, 7, 788, 388, 20, 324, 56, 26262, 705, 149, 40, 342, 282, 5, 2639, 18, 428, 5, 65, 9, 19, 59, 10637, 5, 659, 249, 31, 10, 143, 347, 5, 32, 32, 11, 15, 14065, 8, 17, 12]),\n",
              "       list([1, 346, 273, 94, 187, 53, 74, 472, 26, 14, 46, 19, 124, 15, 39, 74, 32, 6582, 18, 14, 46, 61, 6097, 18, 1730, 1668, 32, 11, 14, 996, 12, 11, 123, 346, 39, 235, 627, 276, 5, 19, 19, 11, 15, 17, 12]),\n",
              "       list([1, 1228, 81, 8, 261, 524, 10, 384, 292, 322, 5, 4, 49, 31, 10, 323, 5, 1400, 103, 450, 16, 8, 1400, 381, 69, 928, 20, 5, 1228, 80, 480, 10, 334, 116, 9, 100, 766, 157, 7, 4, 29, 31, 4, 1395, 5, 4, 587, 1400, 33, 2356, 6, 219, 767, 15, 10, 67, 6, 4, 1004, 1228, 261, 17, 12]),\n",
              "       list([1, 67, 416, 170, 54, 1223, 27, 356, 697, 81, 13161, 215, 8, 4, 116, 23, 3283, 8, 3522, 12484, 42, 559, 31, 1009, 716, 1578, 1838, 24, 16, 535, 45, 2746, 4, 834, 1802, 117, 4, 326, 2349, 347, 267, 21, 186, 828, 9668, 50, 40, 63, 61, 11, 79, 335, 34, 238, 28, 722, 19, 63, 233, 12, 63, 9668, 826, 195, 5, 313, 7135, 27569, 8, 36, 114, 45, 594, 21, 4, 9148, 5, 4, 116, 58, 21, 185, 4, 166, 41, 668, 6, 888, 16, 12484, 8, 24, 184, 9668, 34, 238, 28, 210, 492, 15, 10, 67, 28, 4, 216, 5, 4, 615, 416, 25, 1020, 24, 314, 289, 5, 266, 186, 1423, 1014, 25, 347, 9668, 8, 25, 390, 98, 186, 41, 1740, 215, 1423, 5, 296, 6, 124, 26, 10, 67, 28, 24, 96, 9668, 114, 1070, 10, 80, 96, 7, 4, 456, 22581, 12484, 8, 1578, 553, 25, 89, 186, 862, 13, 4, 2050, 362, 907, 6, 19, 279, 15, 10, 67, 22, 19, 119, 15, 21, 4, 17213, 36, 8, 16, 2351, 25, 448, 5692, 6, 19, 512, 15, 10, 67, 22, 19, 482, 15, 7, 788, 215, 8, 4, 7923, 2050, 362, 218, 1043, 922, 159, 917, 4, 182, 40, 3020, 22, 158, 6, 352, 20, 117, 4, 54, 142, 206, 267, 21, 186, 90, 67, 8, 5856, 19657, 42, 559, 31, 4296, 3367, 9, 111, 4, 182, 23, 133, 6, 351, 815, 28, 102, 6, 352, 20, 117, 4, 225, 142, 206, 36, 8, 12484, 8, 4, 688, 150, 10, 67, 116, 58, 2304, 11, 15, 135, 41, 30, 10, 7096, 13, 356, 697, 4, 1697, 9, 387, 49, 41, 286, 276, 4358, 172, 10, 1787, 218, 9, 3685, 419, 538, 1469, 36, 8, 356, 697, 40, 432, 55, 6709, 6, 30, 126, 2482, 15980, 30377, 692, 5, 25, 595, 36, 8, 28383, 21911, 4611, 195, 5, 29555, 65, 111, 24315, 50, 1043, 10, 124, 47, 20, 310, 7, 9668, 8, 54, 121, 356, 8568, 116, 34, 8197, 3283, 17, 12]),\n",
              "       list([1, 178, 53, 279, 26, 14, 124, 26, 178, 39, 19, 4481, 18, 14, 19, 4737, 18, 86, 187, 61, 11, 14, 160, 70, 11, 180, 183, 12, 4090, 5007, 14, 12, 2713, 628, 29, 178, 53, 462, 26, 14, 472, 26, 178, 39, 32, 4253, 18, 14, 19, 1890, 18, 86, 688, 70, 11, 14, 352, 61, 11, 180, 183, 12, 5219, 5350, 14, 12, 4400, 5306, 123, 29, 301, 1025, 1532, 627, 276, 5, 19, 19, 11, 15, 58, 156, 26, 53, 235, 629, 5, 5432, 18, 15, 14, 68, 11, 15, 7, 346, 9, 32, 32, 11, 15, 14, 19, 19, 11, 15, 7, 29, 22, 131, 46, 2555, 17, 12]),\n",
              "       list([1, 4, 30097, 106, 8, 16, 33, 8017, 4, 278, 324, 60, 20166, 4, 895, 390, 473, 1677, 75, 1452, 42, 698, 11, 3556, 197, 7457, 6, 1671, 197, 1245, 692, 24, 9687, 185, 4, 60, 1176, 639, 11, 1210, 7, 10, 871, 417, 1939, 78, 206, 301, 20166, 791, 20843, 29509, 118, 371, 4, 534, 6, 8017, 4, 60, 34, 10, 1908, 9, 24, 127, 171, 64, 414, 1592, 128, 7, 908, 10, 67, 10, 98, 5, 4, 68, 35, 3556, 135, 67, 244, 33, 30, 554, 6, 127, 640, 106, 173, 8, 17, 12]),\n",
              "       list([1, 53, 46, 258, 26, 14, 46, 32, 539, 15, 39, 46, 19, 1193, 18, 14, 46, 165, 4692, 18, 86, 19, 7929, 18, 14, 19, 6190, 18, 29, 53, 46, 745, 26, 14, 46, 32, 492, 15, 39, 46, 12, 7499, 18, 14, 46, 165, 4215, 18, 86, 47, 5736, 18, 14, 59, 5210, 18, 17, 12]),\n",
              "       list([1, 53, 46, 312, 26, 14, 74, 134, 26, 39, 46, 5775, 18, 14, 74, 19, 3843, 18, 86, 981, 19, 11, 14, 924, 19, 11, 155, 230, 53, 74, 321, 26, 14, 74, 119, 26, 39, 74, 32, 5328, 18, 14, 74, 32, 3253, 18, 86, 2389, 44, 11, 14, 2012, 61, 11, 17, 12])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiCULh5tAoC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word_index[1]\n",
        "#inv_word_map = {v: k for k, v in word_map.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6W8v9-cF27a",
        "colab_type": "code",
        "outputId": "7c4b00fb-c293-43b3-abdd-17f86e824780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18,  3,  3,  9, 19, 19,  4,  4, 11,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "f6bb327c-20dd-4ed3-84f5-422bfe8a9abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVSlFEAqWJM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9851ee3-d001-45d9-d0ab-53c3f47cb6a8"
      },
      "source": [
        "# Do not change this line. You need the +1 for some reason. \n",
        "max_features = len(word_index.values()) + 1\n",
        "\n",
        "# TODO - your code!\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout\n",
        "from keras.layers import LSTM\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4_sJQsUGAnr",
        "colab_type": "code",
        "outputId": "b5e6055b-f967-4a74-a9aa-8f78ca73ae31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "lstm = Sequential()\n",
        "lstm.add(Embedding(max_features, 128))\n",
        "lstm.add(LSTM(128))\n",
        "lstm.add(Dropout(0.25))\n",
        "lstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm.compile(loss='binary_crossentropy',\n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "lstm.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         3965440   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 4,097,153\n",
            "Trainable params: 4,097,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4mS_tfB40kP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e32acead-1030-4ca9-ed2b-376a18d4a057"
      },
      "source": [
        "#Notes: place 46 for the output in the dense layer, instead of 1\n",
        "#Also change loss to sparse_categorical_crossentropy\n",
        "#Change to softmax as categorical\n",
        "lstm = Sequential()\n",
        "lstm.add(Embedding(max_features, 128))\n",
        "lstm.add(LSTM(128))\n",
        "lstm.add(Dropout(0.25))\n",
        "lstm.add(Dense(46, activation='softmax'))\n",
        "\n",
        "lstm.compile(loss='sparse_categorical_crossentropy',\n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "lstm.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 46)                5934      \n",
            "=================================================================\n",
            "Total params: 2,697,518\n",
            "Trainable params: 2,697,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjlhOXZa6d2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1422404-cf7b-489b-9a8a-8ac79de611ed"
      },
      "source": [
        "#to find out how many unique values in y train prior to figuring out how many dense layer uniques, do this:\n",
        "import numpy as np\n",
        "len(np.unique(y_train))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4dPqN3VGc29",
        "colab_type": "code",
        "outputId": "9f61f404-56de-452b-b7bb-fea599245029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "print('Train...')\n",
        "lstm.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=5,\n",
        "          validation_data=(X_test, y_test))\n",
        "score, acc = lstm.evaluate(X_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/5\n",
            "8982/8982 [==============================] - 33s 4ms/step - loss: 2.2582 - accuracy: 0.4255 - val_loss: 1.7713 - val_accuracy: 0.5169\n",
            "Epoch 2/5\n",
            "8982/8982 [==============================] - 32s 4ms/step - loss: 1.7054 - accuracy: 0.5593 - val_loss: 1.6198 - val_accuracy: 0.5775\n",
            "Epoch 3/5\n",
            "8982/8982 [==============================] - 32s 4ms/step - loss: 1.4497 - accuracy: 0.6202 - val_loss: 1.4712 - val_accuracy: 0.6251\n",
            "Epoch 4/5\n",
            "8982/8982 [==============================] - 32s 4ms/step - loss: 1.1647 - accuracy: 0.6949 - val_loss: 1.4249 - val_accuracy: 0.6469\n",
            "Epoch 5/5\n",
            "8982/8982 [==============================] - 32s 4ms/step - loss: 0.9468 - accuracy: 0.7564 - val_loss: 1.3990 - val_accuracy: 0.6665\n",
            "2246/2246 [==============================] - 1s 350us/step\n",
            "Test score: 1.3989664372438209\n",
            "Test accuracy: 0.6665182709693909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMXIfk3z-7FR",
        "colab_type": "code",
        "outputId": "d011976f-24a0-4382-8fe3-fbce2be77108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "print('x_train shape:', X_train.shape)\n",
        "print('x_test shape:', X_test.shape)\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print('Train...')\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=5,\n",
        "          validation_data=(X_test, y_test))\n",
        "score, acc = model.evaluate(X_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8982 train sequences\n",
            "2246 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (8982, 80)\n",
            "x_test shape: (2246, 80)\n",
            "Build model...\n",
            "Train...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/5\n",
            "2816/8982 [========>.....................] - ETA: 29s - loss: -112.3260 - accuracy: 0.0465"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0d1cd937f93f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     33\u001b[0m score, acc = model.evaluate(X_test, y_test,\n\u001b[1;32m     34\u001b[0m                             batch_size=batch_size)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "1upEhq2A7brj",
        "colab_type": "text"
      },
      "source": [
        "## Sequence Data Question\n",
        "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
        "\n",
        "Used to ensure all sequences in a list have the same length\n",
        "makes it possible to do batch training \n",
        "\n",
        "\n",
        "\n",
        "## RNNs versus LSTMs\n",
        "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
        "\n",
        "LSTMs can access earlier layers whereas RNNs can only remember the last layers\n",
        "This is a very important property when we need the prediction of the neural network to depend on the historical context of inputs, rather than only on the very last input.\n",
        "\n",
        "\n",
        "\n",
        "## RNN / LSTM Use Cases\n",
        "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
        "LSTM:\n",
        "For Shakespeare text generation by looking at text and then predicting what the next characters will look like\n",
        "\n",
        "For music generation by learning against musical notes\n",
        "\n",
        "For handwriting generation by learning against hand written letters\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and [ResNet50v2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2) (pre-trained) to detect which of the images with the `frog_images` subdirectory has a frog in it. Note: You will need to upload the images to Colab. \n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGjxIFyb7brl",
        "colab_type": "text"
      },
      "source": [
        "The skimage function below will help you read in all the frog images into memory at once. You should use the preprocessing functions that come with ResnetV2 to help resize the images prior to inference. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SY9tEtELPWE",
        "colab_type": "code",
        "outputId": "148f6e93-b19e-411b-8595-ed319711c664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19AVlp6tNEtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread_collection\n",
        "\n",
        "images = imread_collection('/content/drive/My Drive/Lambda/frog_images/*.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERca6DgyNndq",
        "colab_type": "code",
        "outputId": "1dc6785d-589e-43e6-907b-cdb01fcdfc47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images[2].shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3456, 4608, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "988ea066-5739-490a-def9-42fa9edff6dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(type(images))\n",
        "print(type(images[0]), end=\"\\n\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'skimage.io.collection.ImageCollection'>\n",
            "<class 'numpy.ndarray'>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "Your goal is to validly run ResNet50v2 on the input images - don't worry about tuning or improving the model. Print out the predictions in any way you see fit. \n",
        "\n",
        "*Hint* - ResNet 50v2 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goals:* \n",
        "- Check for other things such as fish.\n",
        "- Print out the image with its predicted label\n",
        "- Wrap everything nicely in well documented fucntions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaT07ddW3nHz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "945065ef-1c36-4963-f7b4-ef0219a4f545"
      },
      "source": [
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input\n",
        "# TODO - your code!\n",
        "\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "model = ResNet50V2(\n",
        "                   include_top=False,\n",
        "                   weights='imagenet')\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz27_u47PpW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#add\n",
        "from skimage.transform import resize\n",
        "\n",
        "def process_img_path(img_path):\n",
        "    return image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "def img_contains_frog(img):\n",
        "    #resizing\n",
        "    x = resize(img /255., (224, 224))\n",
        "    #x = image.img_to_array(x)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    #x = preprocess_input(x)\n",
        "\n",
        "    features = model.predict(x)\n",
        "\n",
        "    results = decode_predictions(features, top=3)[0]\n",
        "    #print(results)\n",
        "    #for entry in results:\n",
        "        #if entry[1] == 'frog':\n",
        "            #return entry[2]\n",
        "    #return 0.0\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x4yIJs4PJrP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "130deea5-1272-4ff4-9014-b820374c11b9"
      },
      "source": [
        "img_contains_frog(images[1])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('n01641577', 'bullfrog', 0.8454136),\n",
              " ('n04090263', 'rifle', 0.051359806),\n",
              " ('n02655020', 'puffer', 0.028388854)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-2M_XfdNKHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a1ae4616-749e-4ff0-9bba-7dbd5406ddf6"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "model = ResNet50V2(weights='imagenet')\n",
        "def process_img_path(img_path):\n",
        "    return image.load_img(img_path)\n",
        "def img_contains_frog(img):\n",
        "    x = resize(img /255., (224,224)) \n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    #x = preprocess_input(x)\n",
        "    features = model.predict(x)\n",
        "    results = decode_predictions(features, top=3)[0]\n",
        "    for entry in results:\n",
        "        if entry[1] in ('bullfrog', 'tree frog', 'tailed frog'):\n",
        "            frog = True\n",
        "        else:\n",
        "            frog = entry[1]\n",
        "    return frog"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102875136/102869336 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0RvAhePNbOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frogs = {}\n",
        "for id_, image in enumerate(images):\n",
        "    frogs[id_] = img_contains_frog(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNUP4CaxR-et",
        "colab_type": "code",
        "outputId": "eabb812c-9f98-43a0-ec04-b218febbee8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_contains_frog(images[2])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cicada'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSvkEuHJN8oI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "cbd5bd8a-01aa-48bd-b518-686c397fcc33"
      },
      "source": [
        "#img_contains_frog()\n",
        "for image in images:\n",
        "  print(img_contains_frog(image))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pot\n",
            "puffer\n",
            "cicada\n",
            "Petri_dish\n",
            "binder\n",
            "True\n",
            "True\n",
            "jellyfish\n",
            "American_alligator\n",
            "vase\n",
            "hip\n",
            "gar\n",
            "greenhouse\n",
            "tray\n",
            "green_lizard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HszrN8v8himy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "def process_img_path(img_path):\n",
        "    return image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "def img_contains_frog2(img):\n",
        "    #x = image.img_to_array(img)\n",
        "    x = np.expand_dims(img, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    model = ResNet50(weights='imagenet')\n",
        "    features = model.predict(x)\n",
        "    results = decode_predictions(features, top=3)[0]\n",
        "    print(results)\n",
        "    for entry in results:\n",
        "        if entry[1].find('frog') > 0:\n",
        "            return entry[2]\n",
        "    return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzcd_fD0h0AN",
        "colab_type": "code",
        "outputId": "6a7426ec-9c42-4068-bfb1-c083deced133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "img_contains_frog2(images[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 2s 0us/step\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_2:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2137, 1710, 3).\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "[('n01930112', 'nematode', 0.032350022), ('n01496331', 'electric_ray', 0.015001914), ('n03445777', 'golf_ball', 0.014543021)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty8wa9tRirqM",
        "colab_type": "code",
        "outputId": "1f0b0825-1b70-4795-b997-ec6dd7e81688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "img_contains_frog2(images[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_5:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3810, 2856, 3).\n",
            "[('n09472597', 'volcano', 0.12513255), ('n01930112', 'nematode', 0.08108736), ('n03773504', 'missile', 0.048901953)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k64ittbCjBpE",
        "colab_type": "code",
        "outputId": "7e3f7de0-f2e7-4362-e102-7b51238bb20c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "img_contains_frog2(images[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_6:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3456, 4608, 3).\n",
            "[('n01930112', 'nematode', 0.15511686), ('n04525038', 'velvet', 0.07890502), ('n02219486', 'ant', 0.029604794)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzFouqrYjJcO",
        "colab_type": "code",
        "outputId": "53e08377-70a2-4d9e-c983-2fdcbc063849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "img_contains_frog2(images[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_8:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2500, 3335, 3).\n",
            "[('n02219486', 'ant', 0.12076042), ('n02233338', 'cockroach', 0.040772017), ('n02259212', 'leafhopper', 0.038669467)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1cjStE-jJlW",
        "colab_type": "code",
        "outputId": "278cb9e7-f009-44e4-99bc-4d73a01f7f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "img_contains_frog2(images[4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_9:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2000, 3008, 3).\n",
            "[('n03196217', 'digital_clock', 0.10913357), ('n01833805', 'hummingbird', 0.06624019), ('n01873310', 'platypus', 0.042204827)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmTNaW7ajJr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#attempt at resize\n",
        "from skimage.transform import resize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5czcFFOjJzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X = resize(X, (520,256,256,3))\n",
        "#(2137, 1710, 3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnxTtCDYjJ6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image0 = resize(images[0],(224,224,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY2P84hUmDsp",
        "colab_type": "code",
        "outputId": "cfe3ff59-947f-49cc-b255-4bb70280501b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "img_contains_frog2(resize(images[1],(224,224,3)))\n",
        "for image in images:\n",
        "  img_contains_frog2(resize(image,(224,224,3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('n03729826', 'matchstick', 0.059754852), ('n06359193', 'web_site', 0.055888206), ('n03196217', 'digital_clock', 0.047033764)]\n",
            "[('n06359193', 'web_site', 0.062323112), ('n03196217', 'digital_clock', 0.05368565), ('n01930112', 'nematode', 0.05281234)]\n",
            "[('n03729826', 'matchstick', 0.059754852), ('n06359193', 'web_site', 0.055888206), ('n03196217', 'digital_clock', 0.047033764)]\n",
            "[('n06359193', 'web_site', 0.05612781), ('n03729826', 'matchstick', 0.051401448), ('n03196217', 'digital_clock', 0.0493269)]\n",
            "[('n06359193', 'web_site', 0.06295727), ('n01930112', 'nematode', 0.05260743), ('n03196217', 'digital_clock', 0.04884174)]\n",
            "[('n06359193', 'web_site', 0.06480381), ('n01930112', 'nematode', 0.049625926), ('n03196217', 'digital_clock', 0.045141205)]\n",
            "[('n06359193', 'web_site', 0.06242961), ('n03196217', 'digital_clock', 0.046222176), ('n01930112', 'nematode', 0.04373117)]\n",
            "[('n06359193', 'web_site', 0.055801474), ('n03196217', 'digital_clock', 0.05542864), ('n03729826', 'matchstick', 0.0528601)]\n",
            "[('n03729826', 'matchstick', 0.05113954), ('n06359193', 'web_site', 0.04858198), ('n03196217', 'digital_clock', 0.04785696)]\n",
            "[('n06359193', 'web_site', 0.07434836), ('n01930112', 'nematode', 0.053617623), ('n03196217', 'digital_clock', 0.04667002)]\n",
            "[('n06359193', 'web_site', 0.06386194), ('n01930112', 'nematode', 0.04848813), ('n03196217', 'digital_clock', 0.04335035)]\n",
            "[('n06359193', 'web_site', 0.0648597), ('n01930112', 'nematode', 0.048753846), ('n03196217', 'digital_clock', 0.044015847)]\n",
            "[('n06359193', 'web_site', 0.059280746), ('n03729826', 'matchstick', 0.05076437), ('n01930112', 'nematode', 0.050515868)]\n",
            "[('n03729826', 'matchstick', 0.052103925), ('n04404412', 'television', 0.03866146), ('n03196217', 'digital_clock', 0.03816863)]\n",
            "[('n06359193', 'web_site', 0.062437538), ('n03196217', 'digital_clock', 0.054235496), ('n01930112', 'nematode', 0.04584514)]\n",
            "[('n06359193', 'web_site', 0.066113755), ('n01930112', 'nematode', 0.052815087), ('n03196217', 'digital_clock', 0.04668727)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kfFTfuioW7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
        "\n",
        "__*Your Answer:*__ \n",
        "An example is learning the representation of MNIST numbers and then recognizing them in handwritten exmaples of these numbers\n",
        "\n",
        "Here's another exmaple \"Collaborative Filtering is a method used by recommender systems to make predictions about the interest of a specific user by collecting taste or preference information from many other users. The technique of Collaborative Filtering has the underlying assumption that if a user A has the same taste or opinion on an issue as the person B, A is more likely to have B’s opinion on a different issue.\n",
        "In this article, you will learn how to predict the ratings a user would give a movie based on this user’s taste and the taste of other users who watched and rated the same and other movies.\" https://towardsdatascience.com/deep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist?\n",
        "Just learning to get the hang of it. Very basic skillset\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "CNNs for Perception, I want to use it at work\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "AGI is getting closer. So is self-driving car\n",
        "- What are the threats posed by AI to our society?'\n",
        "mimicking our voices, mimicking videos, mimicking other humans and pretending to be us\n",
        "- How do you think we can counteract those threats? \n",
        "By imposing ethical standards through commitees and government acceptance of best practices across all nations of the world. Having online units to counteract AI that is a threat\n",
        "- Do you think achieving General Artifical Intelligence is ever possible?\n",
        "Yes, in the next 10 years we'll get there\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yYZV0R57brz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}